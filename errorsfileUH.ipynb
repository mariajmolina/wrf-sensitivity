{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "from math import sqrt\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(observed, modeled):\n",
    "    #classic rmse\n",
    "    observed = observed.flatten()\n",
    "    modeled = modeled.flatten()\n",
    "    return np.sqrt(((observed - modeled) ** 2).mean())\n",
    "\n",
    "\n",
    "def rmse_ref(observed, modeled):\n",
    "    #for fss denominator\n",
    "    total_gridcells = len(observed.flatten())\n",
    "    return np.sqrt((np.nansum(observed**2) + np.nansum(modeled**2))/total_gridcells)\n",
    "\n",
    "\n",
    "def mse(observed, modeled):\n",
    "    #classic rmse\n",
    "    observed = observed.flatten()\n",
    "    modeled = modeled.flatten()\n",
    "    return ((observed - modeled) ** 2).mean()\n",
    "\n",
    "\n",
    "def mse_ref(observed, modeled):\n",
    "    #for fss denominator\n",
    "    total_gridcells = len(observed.flatten())\n",
    "    return (np.nansum(observed**2) + np.nansum(modeled**2))/total_gridcells\n",
    "\n",
    "\n",
    "def compute_sns(ob_file, model_file):\n",
    "        \n",
    "    d_record = 1 - (rmse(ob_file, model_file)/rmse_ref(ob_file, model_file))\n",
    "    d2_record = 1 - (mse(ob_file, model_file)/mse_ref(ob_file, model_file))\n",
    "        \n",
    "    return d_record, d2_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_errors(wrf_file_folder_choice, UH_threshold, dbz_threshold, binary=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to compute sns, rmse, and mse and save the final output as a netCDF file.\n",
    "    \"\"\"\n",
    "   \n",
    "    def hypot(a,b):\n",
    "        \"\"\"\n",
    "        Compute hypotenuse for radius of interest in regridding step for sns.\n",
    "        \"\"\"\n",
    "        return sqrt(a**2 + b**2)\n",
    "\n",
    "    data = xr.open_dataset('/glade/work/molina/DATA/jan2017_synoptic/'+wrf_file_folder_choice+'/ver_grid_20_UH_'+str(UH_threshold)+'_Z_'+str(dbz_threshold)+'.nc')\n",
    "  \n",
    "    data_proxy = data.UHdbz_mask\n",
    "    data_tors = data.tors_mask\n",
    "\n",
    "    stagger = np.arange(1,140,1)\n",
    "\n",
    "    thesns_rmse = np.zeros((len(stagger)))\n",
    "    thesns_mse = np.zeros((len(stagger)))\n",
    "    thermse = np.zeros((len(stagger)))\n",
    "    themse = np.zeros((len(stagger)))\n",
    "\n",
    "    i_grid, j_grid = np.indices(data_proxy[:,:].shape[:])\n",
    "\n",
    "    #grab the values\n",
    "    max_proxy = data_proxy\n",
    "    #grab values where the threshold is exceeded\n",
    "    max_points_proxy = np.array(np.where(max_proxy >= 1)).T\n",
    "    #create kdtree using max points\n",
    "    max_tree_proxy = cKDTree(max_points_proxy)\n",
    "\n",
    "    #grab the values\n",
    "    max_tors = data_tors\n",
    "    #grab values where the threshold is exceeded\n",
    "    max_points_tors = np.array(np.where(max_tors >= 1)).T\n",
    "    #create kdtree using max points\n",
    "    max_tree_tors = cKDTree(max_points_tors)\n",
    "\n",
    "    binary = True\n",
    "\n",
    "    for num, stag in enumerate(stagger):\n",
    "\n",
    "        #create the new grid\n",
    "        stagger_points_proxy = np.vstack((i_grid[::stag, ::stag].ravel(), j_grid[::stag, ::stag].ravel())).T\n",
    "        stagger_points_tors = np.vstack((i_grid[::stag, ::stag].ravel(), j_grid[::stag, ::stag].ravel())).T\n",
    "        valid_stagger_points_proxy = np.zeros(stagger_points_proxy.shape[0])\n",
    "        valid_stagger_points_tors = np.zeros(stagger_points_tors.shape[0])\n",
    "        stagger_tree_proxy = cKDTree(stagger_points_proxy)\n",
    "        stagger_tree_tors = cKDTree(stagger_points_tors)\n",
    "\n",
    "        if len(max_points_proxy) != 0:\n",
    "            hit_points_proxy = np.unique(np.concatenate(max_tree_proxy.query_ball_tree(stagger_tree_proxy, hypot(stag,stag))))\n",
    "            hit_points_tors = np.unique(np.concatenate(max_tree_tors.query_ball_tree(stagger_tree_tors, hypot(stag,stag))))\n",
    "            if not binary:\n",
    "                valid_stagger_points_proxy[hit_points_proxy.astype(int)] += 1\n",
    "                valid_stagger_points_tors[hit_points_tors.astype(int)] += 1\n",
    "                surrogate_grid_proxy = valid_stagger_points_proxy.reshape(i_grid[::stag, ::stag].shape) \n",
    "                surrogate_grid_tors = valid_stagger_points_tors.reshape(i_grid[::stag, ::stag].shape) \n",
    "            if binary:\n",
    "                valid_stagger_points_proxy[hit_points_proxy.astype(int)] = 1\n",
    "                valid_stagger_points_tors[hit_points_tors.astype(int)] = 1\n",
    "                surrogate_grid_proxy = valid_stagger_points_proxy.reshape(i_grid[::stag, ::stag].shape) \n",
    "                surrogate_grid_tors = valid_stagger_points_tors.reshape(i_grid[::stag, ::stag].shape) \n",
    "\n",
    "        thesns_rmse[num], thesns_mse[num] = compute_sns(valid_stagger_points_proxy, valid_stagger_points_tors)\n",
    "        thermse[num] = rmse(valid_stagger_points_proxy, valid_stagger_points_tors)\n",
    "        themse[num] = mse(valid_stagger_points_proxy, valid_stagger_points_tors)\n",
    "    \n",
    "    thedata = xr.Dataset({'sns_rmse':(['x'],thesns_rmse),\n",
    "                          'sns_mse':(['x'],thesns_mse),\n",
    "                          'rmse':(['x'],thesns_rmse),\n",
    "                          'mse':(['x'],thesns_rmse)},\n",
    "                        attrs={'File Author':'Maria J. Molina'})\n",
    "\n",
    "    thedata.to_netcdf('/glade/work/molina/DATA/jan2017_synoptic/'+wrf_file_folder_choice+'/errors_file_UH_'+str(UH_threshold)+'_Z_'+str(dbz_threshold)+'.nc')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing UH:100 and dbz:50\n",
      "Computing UH:100 and dbz:40\n",
      "Computing UH:100 and dbz:30\n",
      "Computing UH:80 and dbz:50\n",
      "Computing UH:80 and dbz:40\n",
      "Computing UH:80 and dbz:30\n",
      "Computing UH:60 and dbz:50\n",
      "Computing UH:60 and dbz:40\n",
      "Computing UH:60 and dbz:30\n",
      "Computing UH:40 and dbz:50\n",
      "Computing UH:40 and dbz:40\n",
      "Computing UH:40 and dbz:30\n"
     ]
    }
   ],
   "source": [
    "#wrf_file_folder_choice = 'wrf4km_ens_1'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_2'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_3'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_4'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_5'\n",
    "wrf_file_folder_choice = 'wrf4km_ens_6'\n",
    "\n",
    "UH_thresholds = np.array([100,100,100,80,80,80,60,60,60,40,40,40])\n",
    "dbz_thresholds = np.array([50,40,30,50,40,30,50,40,30,50,40,30])\n",
    "\n",
    "for UH_threshold, dbz_threshold in zip(UH_thresholds, dbz_thresholds):\n",
    "    print(f\"Computing UH:{UH_threshold} and dbz:{dbz_threshold}\")\n",
    "    computing_errors(wrf_file_folder_choice, UH_threshold, dbz_threshold, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10",
   "language": "python",
   "name": "cmip6-201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
