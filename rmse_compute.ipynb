{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from wrf import to_np, getvar, get_basemap, latlon_coords\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from itertools import product\n",
    "import math\n",
    "import xarray as xr\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "#functions for creating a tornado track\n",
    "\n",
    "def getPathLength(lat1,lng1,lat2,lng2):\n",
    "    '''calculates the distance between two lat, long coordinate pairs'''\n",
    "    R = 6371000 # radius of earth in m\n",
    "    lat1rads = math.radians(lat1)\n",
    "    lat2rads = math.radians(lat2)\n",
    "    deltaLat = math.radians((lat2-lat1))\n",
    "    deltaLng = math.radians((lng2-lng1))\n",
    "    a = math.sin(deltaLat/2) * math.sin(deltaLat/2) + math.cos(lat1rads) * math.cos(lat2rads) * math.sin(deltaLng/2) * math.sin(deltaLng/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = R * c\n",
    "    return d\n",
    "\n",
    "def getDestinationLatLong(lat,lng,azimuth,distance):\n",
    "    '''returns the lat an long of destination point \n",
    "    given the start lat, long, aziuth, and distance'''\n",
    "    R = 6378.1 #Radius of the Earth in km\n",
    "    brng = math.radians(azimuth) #Bearing is degrees converted to radians.\n",
    "    d = distance/1000 #Distance m converted to km\n",
    "    lat1 = math.radians(lat) #Current dd lat point converted to radians\n",
    "    lon1 = math.radians(lng) #Current dd long point converted to radians\n",
    "    lat2 = math.asin(math.sin(lat1) * math.cos(d/R) + math.cos(lat1)* math.sin(d/R)* math.cos(brng))\n",
    "    lon2 = lon1 + math.atan2(math.sin(brng) * math.sin(d/R)* math.cos(lat1), math.cos(d/R)- math.sin(lat1)* math.sin(lat2))\n",
    "    #convert back to degrees\n",
    "    lat2 = math.degrees(lat2)\n",
    "    lon2 = math.degrees(lon2)\n",
    "    return[lat2, lon2]\n",
    "\n",
    "def calculateBearing(lat1,lng1,lat2,lng2):\n",
    "    '''calculates the azimuth in degrees from start point to end point'''\n",
    "    startLat = math.radians(lat1)\n",
    "    startLong = math.radians(lng1)\n",
    "    endLat = math.radians(lat2)\n",
    "    endLong = math.radians(lng2)\n",
    "    dLong = endLong - startLong\n",
    "    dPhi = math.log(math.tan(endLat/2.0+math.pi/4.0)/math.tan(startLat/2.0+math.pi/4.0))\n",
    "    if abs(dLong) > math.pi:\n",
    "         if dLong > 0.0:\n",
    "             dLong = -(2.0 * math.pi - dLong)\n",
    "         else:\n",
    "             dLong = (2.0 * math.pi + dLong)\n",
    "    bearing = (math.degrees(math.atan2(dLong, dPhi)) + 360.0) % 360.0;\n",
    "    return bearing\n",
    "\n",
    "def main(interval,lat1,lng1,lat2,lng2):\n",
    "    '''returns every coordinate pair inbetween two coordinate \n",
    "    pairs given the desired interval (in meters!).'''\n",
    "\n",
    "    d = getPathLength(lat1,lng1,lat2,lng2)\n",
    "    remainder, dist = math.modf((d / interval))\n",
    "    counter = float(interval)\n",
    "    coords = []\n",
    "    coords.append([lat1,lng1])\n",
    "    \n",
    "    azimuth = calculateBearing(lat1,lng1,lat2,lng2)\n",
    "    \n",
    "    for distance in range(0,int(dist)):\n",
    "        coord = getDestinationLatLong(lat1,lng1,azimuth,counter)\n",
    "        counter = counter + float(interval)\n",
    "        coords.append(coord)\n",
    "    coords.append([lat2,lng2])\n",
    "    return np.array(coords)\n",
    "\n",
    "\n",
    "def sliding_window(arr, window_size):\n",
    "    \"\"\" Construct a sliding window view of the array\"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    window_size = int(window_size)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(\"need 2-D input\")\n",
    "    if not (window_size > 0):\n",
    "        raise ValueError(\"need a positive window size\")\n",
    "    shape = (arr.shape[0] - window_size + 1,\n",
    "             arr.shape[1] - window_size + 1,\n",
    "             window_size, window_size)\n",
    "    if shape[0] <= 0:\n",
    "        shape = (1, shape[1], arr.shape[0], shape[3])\n",
    "    if shape[1] <= 0:\n",
    "        shape = (shape[0], 1, shape[2], arr.shape[1])\n",
    "    strides = (arr.shape[1]*arr.itemsize, arr.itemsize,\n",
    "               arr.shape[1]*arr.itemsize, arr.itemsize)\n",
    "    return as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def cell_neighbors(arr, i, j, d):\n",
    "    \"\"\"Return d-th neighbors of cell (i, j)\"\"\"\n",
    "    w = sliding_window(arr, 2*d+1)\n",
    "    ix = np.clip(i - d, 0, w.shape[0]-1)\n",
    "    jx = np.clip(j - d, 0, w.shape[1]-1)\n",
    "    i0 = max(0, i - d - ix)\n",
    "    j0 = max(0, j - d - jx)\n",
    "    i1 = w.shape[2] - max(0, d - i + ix)\n",
    "    j1 = w.shape[3] - max(0, d - j + jx)\n",
    "    return w[int(ix), int(jx)][int(i0):int(i1),int(j0):int(j1)].ravel()\n",
    "\n",
    "def rmse(observed, modeled):\n",
    "    #classic rmse\n",
    "    observed = observed.flatten()\n",
    "    modeled = modeled.flatten()\n",
    "    return np.sqrt(((observed - modeled) ** 2).mean())\n",
    "\n",
    "\n",
    "def rmse_ref(observed, modeled):\n",
    "    #for fss denominator\n",
    "    total_gridcells = len(observed.flatten())\n",
    "    return np.sqrt((np.nansum(observed**2) + np.nansum(modeled**2))/total_gridcells)\n",
    "\n",
    "\n",
    "def mse(observed, modeled):\n",
    "    #classic rmse\n",
    "    observed = observed.flatten()\n",
    "    modeled = modeled.flatten()\n",
    "    return ((observed - modeled) ** 2).mean()\n",
    "\n",
    "\n",
    "def mse_ref(observed, modeled):\n",
    "    #for fss denominator\n",
    "    total_gridcells = len(observed.flatten())\n",
    "    return (np.nansum(observed**2) + np.nansum(modeled**2))/total_gridcells\n",
    "\n",
    "\n",
    "def compute_sns(ob_file, model_file, points):\n",
    "    \n",
    "    a = np.arange(0,1000,1)\n",
    "    \n",
    "    odd_values = a[a%2==1]\n",
    "    num_of_grids_square = (a[a%2==1])**2\n",
    "    \n",
    "    d_record = np.zeros(odd_values.shape)\n",
    "    d2_record = np.zeros(odd_values.shape)\n",
    "    \n",
    "    for counter, (d, num_square) in enumerate(zip(a[:odd_values.shape[0]], num_of_grids_square)):\n",
    "        \n",
    "        save_m = []\n",
    "        save_o = []\n",
    "        \n",
    "        for counter_2, p in enumerate(points):\n",
    "            \n",
    "            wut1 = cell_neighbors(model_file, p[0], p[1], d=d)\n",
    "            wut2 = cell_neighbors(ob_file, p[0], p[1], d=d)\n",
    "            \n",
    "            if len(wut1) == num_square:\n",
    "            \n",
    "                #model\n",
    "                fraction_model = np.nansum(wut1)/len(wut1)\n",
    "                save_m.append(fraction_model)\n",
    "            \n",
    "                #observed\n",
    "                fraction_ob = np.nansum(wut2)/len(wut2)\n",
    "                save_o.append(fraction_ob)\n",
    "            \n",
    "        save_m = np.array(save_m)\n",
    "        save_o = np.array(save_o)\n",
    "        \n",
    "        d_record[counter] = 1 - (rmse(save_o, save_m)/rmse_ref(save_o, save_m))\n",
    "        d2_record[counter] = 1 - (mse(save_o, save_m)/mse_ref(save_o, save_m))\n",
    "        \n",
    "    return d_record, d2_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Opened...\n",
      "Tors finished.\n",
      "2017-01-21 09:00:00 complete...\n",
      "2017-01-21 10:00:00 complete...\n",
      "2017-01-21 11:00:00 complete...\n",
      "2017-01-21 12:00:00 complete...\n",
      "2017-01-21 13:00:00 complete...\n",
      "2017-01-21 14:00:00 complete...\n",
      "2017-01-21 15:00:00 complete...\n",
      "2017-01-21 16:00:00 complete...\n",
      "2017-01-21 17:00:00 complete...\n",
      "2017-01-21 18:00:00 complete...\n",
      "2017-01-21 19:00:00 complete...\n",
      "2017-01-21 20:00:00 complete...\n",
      "2017-01-21 21:00:00 complete...\n",
      "2017-01-21 22:00:00 complete...\n",
      "2017-01-21 23:00:00 complete...\n",
      "2017-01-22 00:00:00 complete...\n",
      "2017-01-22 01:00:00 complete...\n",
      "2017-01-22 02:00:00 complete...\n",
      "2017-01-22 03:00:00 complete...\n",
      "2017-01-22 04:00:00 complete...\n",
      "2017-01-22 05:00:00 complete...\n",
      "2017-01-22 06:00:00 complete...\n",
      "2017-01-22 07:00:00 complete...\n",
      "2017-01-22 08:00:00 complete...\n",
      "2017-01-22 09:00:00 complete...\n",
      "2017-01-22 10:00:00 complete...\n",
      "2017-01-22 11:00:00 complete...\n",
      "2017-01-22 12:00:00 complete...\n",
      "2017-01-22 13:00:00 complete...\n",
      "2017-01-22 14:00:00 complete...\n",
      "2017-01-22 15:00:00 complete...\n",
      "2017-01-22 16:00:00 complete...\n",
      "2017-01-22 17:00:00 complete...\n",
      "2017-01-22 18:00:00 complete...\n",
      "2017-01-22 19:00:00 complete...\n",
      "2017-01-22 20:00:00 complete...\n",
      "2017-01-22 21:00:00 complete...\n",
      "2017-01-22 22:00:00 complete...\n",
      "2017-01-22 23:00:00 complete...\n",
      "2017-01-23 00:00:00 complete...\n",
      "2017-01-23 01:00:00 complete...\n",
      "2017-01-23 02:00:00 complete...\n",
      "2017-01-23 03:00:00 complete...\n",
      "2017-01-23 04:00:00 complete...\n",
      "2017-01-23 05:00:00 complete...\n",
      "2017-01-23 06:00:00 complete...\n",
      "2017-01-23 07:00:00 complete...\n",
      "2017-01-23 08:00:00 complete...\n",
      "UH and DBZ finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:116: RuntimeWarning: Mean of empty slice.\n",
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:129: RuntimeWarning: Mean of empty slice.\n",
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Opened...\n",
      "Tors finished.\n",
      "2017-01-21 09:00:00 complete...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a6d2f127036c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muvv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muvv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mmax_UH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muvv_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muvv2_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_UH\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mUH_threshold\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdbz_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdbz_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# Check for all-NaN axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_copyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#computation choosing\n",
    "\n",
    "wrf_file_folder_choice = 'wrf4km_ens_1'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_2'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_3'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_4'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_5'\n",
    "#wrf_file_folder_choice = 'wrf4km_ens_6'\n",
    "\n",
    "choice_res = np.array([80])[0]\n",
    "\n",
    "UH_thresholds = np.array([40,40,40])\n",
    "\n",
    "dbz_thresholds = np.array([50,40,30])\n",
    "\n",
    "\n",
    "#UH_thresholds = np.array([100,100,100,80,80,80,60,60,60,40,40,40])\n",
    "\n",
    "#dbz_thresholds = np.array([50,40,30,50,40,30,50,40,30,50,40,30])\n",
    "\n",
    "\n",
    "Tors = pd.read_csv(r'/glade/work/molina/DATA/jan2017_synoptic/1950-2017_actual_tornadoes_fixed.csv',\n",
    "                   error_bad_lines=False,\n",
    "                   parse_dates=[['mo','dy','yr','time']])\n",
    "\n",
    "Tors = Tors.assign(UTC_time = Tors['mo_dy_yr_time'] + timedelta(hours=6))       \n",
    "Tors = Tors.assign(UTC_yr = Tors['UTC_time'].dt.year) \n",
    "Tors = Tors.assign(UTC_dy = Tors['UTC_time'].dt.day) \n",
    "Tors = Tors.assign(UTC_mo = Tors['UTC_time'].dt.month) \n",
    "Tors = Tors.assign(UTC_hr = Tors['UTC_time'].dt.hour) \n",
    "\n",
    "Tors = Tors[(Tors['UTC_mo']==1)]\n",
    "Tors = Tors[(Tors['UTC_yr']==2017)]\n",
    "\n",
    "Tors = Tors[(Tors['UTC_dy']==21)&(Tors['UTC_hr']>=9)|\n",
    "            (Tors['UTC_dy']==22)|\n",
    "            (Tors['UTC_dy']==23)&(Tors['UTC_hr']<=9)]\n",
    "\n",
    "Tors = Tors[Tors['slat']!=0]\n",
    "Tors = Tors[Tors['slon']!=0]\n",
    "Tors = Tors[(Tors['slat']>=20) & (Tors['slat']<=50)]\n",
    "Tors = Tors[(Tors['slon']>=-130) & (Tors['slon']<=-65)]\n",
    "\n",
    "T_elat = [Tors['slat'].values[u] if i==0 else i for u, i in enumerate(Tors['elat'].values)]\n",
    "T_elon = [Tors['slon'].values[u] if i==0 else i for u, i in enumerate(Tors['elon'].values)]\n",
    "\n",
    "Tors = Tors.assign(corr_elat = T_elat)\n",
    "Tors = Tors.assign(corr_elon = T_elon)\n",
    "\n",
    "Tors = Tors.set_index(['UTC_time']) \n",
    "\n",
    "\n",
    "for UH_threshold, dbz_threshold in zip(UH_thresholds, dbz_thresholds):\n",
    "\n",
    "    file2_wrf_d02 = '/glade/scratch/molina/WRF_HYSPLIT_proj/'+wrf_file_folder_choice+'/wrfout_d01_2017-01-15_09:00:00'\n",
    "    ncfile2_wrf_d02 = Dataset(file2_wrf_d02)\n",
    "    while True:\n",
    "        dbz2_wrf_d02 = np.array([0])\n",
    "        if len(dbz2_wrf_d02) == 1:\n",
    "            try: \n",
    "                dbz2_wrf_d02 = getvar(ncfile2_wrf_d02, \"dbz\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "        if len(dbz2_wrf_d02) != 1:\n",
    "            print('File Opened...')\n",
    "            break\n",
    "    lats4, lons4 = latlon_coords(dbz2_wrf_d02)\n",
    "    m = get_basemap(dbz2_wrf_d02)\n",
    "    xMax, yMax = m(m.urcrnrlon, m.urcrnrlat) \n",
    "    xMin, yMin = m(m.llcrnrlon, m.llcrnrlat) \n",
    "    x_range = (xMax-xMin) / 1000 \n",
    "    y_range = (yMax-yMin) / 1000 \n",
    "    \n",
    "    numXGrids = round(x_range / choice_res + .5,0) \n",
    "    numYGrids = round(y_range / choice_res + .5,0)\n",
    "    xi = np.linspace(xMin, xMax, int(numXGrids))\n",
    "    yi = np.linspace(yMin, yMax, int(numYGrids))\n",
    "    aggregate_grid = np.zeros((yi.shape[0]-1, xi.shape[0]-1)) \n",
    "\n",
    "    for tor_lat1, tor_lon1, tor_lat2, tor_lon2 in zip(Tors['slat'].values, Tors['slon'].values, Tors['corr_elat'].values, Tors['corr_elon'].values): \n",
    "\n",
    "        if tor_lat1 == tor_lat2:\n",
    "            x_values = tor_lon1\n",
    "            y_values = tor_lat1\n",
    "            x_proj, y_proj = m(x_values, y_values) \n",
    "            grid, _, _ = np.histogram2d([y_proj], [x_proj], bins=[yi, xi]) \n",
    "            aggregate_grid[:,:] += grid > 0 \n",
    "\n",
    "        if tor_lat1 != tor_lat2:\n",
    "\n",
    "            coords = main(10000, tor_lat1, tor_lon1, tor_lat2, tor_lon2)        \n",
    "            y_values = coords[:,0]\n",
    "            x_values = coords[:,1]\n",
    "            x_proj, y_proj = m(x_values, y_values)\n",
    "            grid, _, _ = np.histogram2d(y_proj, x_proj, bins=[yi, xi]) \n",
    "            aggregate_grid[:,:] += grid > 0\n",
    "        \n",
    "    print('Tors finished.')\n",
    "    \n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "\n",
    "\n",
    "    #create the range of dates to loop thru wrf files\n",
    "    begdate = datetime.datetime.strptime('2017012109',\"%Y%m%d%H\") \n",
    "    enddate = datetime.datetime.strptime('2017012309',\"%Y%m%d%H\") \n",
    "    monthstr = datetime.datetime.strftime(begdate,\"%B\")\n",
    "    #format into strings\n",
    "    bmonth = '%02d' % begdate.month\n",
    "    bday = '%02d' % begdate.day\n",
    "    bbday = begdate.day\n",
    "    #loop thru hours\n",
    "    dates = []\n",
    "    while begdate < enddate:\n",
    "      dates.append(begdate)\n",
    "      begdate+=datetime.timedelta(hours=1) \n",
    "\n",
    "    uvv_coarse = np.zeros((len(dates),yi.shape[0]-1, xi.shape[0]-1))\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for count, dt in enumerate(dates):\n",
    "\n",
    "      YY = dt.year\n",
    "\n",
    "      MM = \"%02d\"%dt.month\n",
    "      DD = \"%02d\"%dt.day\n",
    "      HH = \"%02d\"%dt.hour\n",
    "\n",
    "      HH_current = dt.hour\n",
    "\n",
    "      if count != 0:\n",
    "          if HH_current != HH_previous:    \n",
    "              counter += 1\n",
    "\n",
    "      wrffile = '/glade/scratch/molina/WRF_HYSPLIT_proj/'+wrf_file_folder_choice+'/wrfout_d01_2017-'+MM+'-'+DD+'_'+HH+':00:00'\n",
    "\n",
    "      if os.path.isfile(wrffile)==True:\n",
    "\n",
    "        ncfile = Dataset(wrffile)\n",
    "\n",
    "        uvv = getvar(ncfile, \"updraft_helicity\", meta=False)\n",
    "        uvv_val = uvv\n",
    "\n",
    "        uvv2 = xr.open_dataset(wrffile, decode_cf=True).UP_HELI_MAX.values[0,:,:]\n",
    "        uvv2_val = uvv2\n",
    "\n",
    "        dbz = getvar(ncfile, \"dbz\", meta=False)\n",
    "        dbz_val = dbz[0,:,:]\n",
    "\n",
    "        for i, j in product(range(0,uvv2.shape[0]), range(0,uvv2.shape[1])):\n",
    "\n",
    "            max_UH = np.nanmax([uvv_val[i,j],uvv2_val[i,j]])\n",
    "\n",
    "            if max_UH >= UH_threshold and dbz_val[i,j] >= dbz_threshold:\n",
    "\n",
    "                latsnow, lonsnow = to_np(lats4)[i,j], to_np(lons4)[i,j]\n",
    "                x_proj,y_proj = m(lonsnow, latsnow)\n",
    "                grid, _, _ = np.histogram2d(np.array([y_proj]),np.array([x_proj]), bins=[yi,xi])\n",
    "\n",
    "                uvv_coarse[counter,:,:] += grid > 0\n",
    "\n",
    "      else:\n",
    "\n",
    "        print(\"file doesn't exist\", os.path.basename(ncfile))\n",
    "\n",
    "      HH_previous = dt.hour\n",
    "\n",
    "      print(str(dt)+' complete...')\n",
    "\n",
    "    print('UH and DBZ finished.')\n",
    "\n",
    "    x1, y1 = xi, yi\n",
    "\n",
    "    x2 = np.zeros(x1.shape)\n",
    "    y2 = np.zeros(y1.shape)\n",
    "    x3 = np.zeros(x1.shape)\n",
    "    y3 = np.zeros(y1.shape)\n",
    "\n",
    "    for i, j in product(range(len(x1)),range(len(y1))):\n",
    "\n",
    "        x2[i], y2[j] = m(x1[i], y1[j], inverse=True)\n",
    "\n",
    "        x2[i] = x2[i]-0.4\n",
    "        y2[j] = y2[j]-0.4\n",
    "\n",
    "        x3[i], y3[j] = m(x2[i], y2[j])\n",
    "\n",
    "    file_tors = np.where(aggregate_grid == 0., aggregate_grid, 1)\n",
    "\n",
    "    file_uhdbz = np.where(np.nansum(uvv_coarse, axis=0) == 0., np.nansum(uvv_coarse, axis=0), 1)        \n",
    "\n",
    "    x4, y4 = x3[1:], y3[1:]\n",
    "\n",
    "    uvv_coarse1 = np.nansum(uvv_coarse, axis=0)\n",
    "\n",
    "\n",
    "    the_mask = xr.open_dataset('/glade/work/molina/DATA/usstates_shapefiles/conus_mask_res_80.nc')\n",
    "    file_tors_pts = []\n",
    "    for k, (i, j) in enumerate(product(range(0,file_tors.shape[0]),range(0,file_tors.shape[1]))):\n",
    "        if the_mask['conus'].values[i,j]:\n",
    "            file_tors_pts.append((i,j))\n",
    "\n",
    "    file_tors_pts = np.array(file_tors_pts)\n",
    "\n",
    "    uhdbz_forrmse_notone = uvv_coarse1[the_mask['conus'].values]\n",
    "    uhdbz_forrmse_one = file_uhdbz[the_mask['conus'].values]\n",
    "    tors_forrmse_notone = aggregate_grid[the_mask['conus'].values]\n",
    "    tors_forrmse_one = file_tors[the_mask['conus'].values]\n",
    "\n",
    "    rmse_notone = rmse(tors_forrmse_notone, uhdbz_forrmse_notone)\n",
    "    rmse_one = rmse(tors_forrmse_one, uhdbz_forrmse_one)      \n",
    "\n",
    "    uhdbz_forsns_notone = np.where(the_mask['conus'].values, uvv_coarse1, 0)\n",
    "    uhdbz_forsns_one = np.where(the_mask['conus'].values, file_uhdbz, 0)\n",
    "    tors_forsns_notone = np.where(the_mask['conus'].values, aggregate_grid, 0)\n",
    "    tors_forsns_one = np.where(the_mask['conus'].values, file_tors, 0)    \n",
    "\n",
    "    sns_notone, fss_notone = np.array(compute_sns(tors_forsns_notone, uhdbz_forsns_notone, file_tors_pts))\n",
    "    sns_one, fss_one = np.array(compute_sns(tors_forsns_one, uhdbz_forsns_one, file_tors_pts))\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    ###############################################################################\n",
    "    ###############################################################################\n",
    "\n",
    "\n",
    "    final_filed = xr.Dataset({'UHdbz_nomask':(['y','x'], uvv_coarse1),\n",
    "                              'UHdbz_mask':(['y','x'], uhdbz_forsns_notone),\n",
    "                              'UHdbz_one_nomask':(['y','x'], file_uhdbz),\n",
    "                              'UHdbz_one_mask':(['y','x'], uhdbz_forsns_one),\n",
    "\n",
    "                              'tors_nomask':(['y','x'], aggregate_grid),\n",
    "                              'tors_mask':(['y','x'], tors_forsns_notone),\n",
    "                              'tors_one_nomask':(['y','x'], file_tors),\n",
    "                              'tors_one_mask':(['y','x'], tors_forsns_one),\n",
    "\n",
    "                              'rmse_notone':(rmse_notone),\n",
    "                              'rmse_one':(rmse_one),\n",
    "\n",
    "                              'sns_notone':(sns_notone),\n",
    "                              'sns_one':(sns_one),\n",
    "\n",
    "                              'fss_notone':(fss_notone),\n",
    "                              'fss_one':(fss_one),                              \n",
    "                              },\n",
    "\n",
    "                              coords={'lon':(['x'],x4),\n",
    "                                      'lat':(['y'],y4)},\n",
    "\n",
    "                              attrs={'File Author':'Maria J. Molina'})\n",
    "\n",
    "\n",
    "    final_filed.to_netcdf('/glade/work/molina/DATA/jan2017_synoptic/'+wrf_file_folder_choice+'/ver_grid_80_UH_'+str(UH_threshold)+'_Z_'+str(dbz_threshold)+'.nc')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uvv_coarse1[the_mask['conus'].values].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34*37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAADrCAYAAABAZosDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEJUlEQVR4nO3dsW5bZRiAYRulJVIyRYqKiKp26s4EqihLL4CRa+jEyHVwGUhdQB2bqQWxsTF1IIoyFbVDASE14rB0itA5tY9D5LzPM/qznd+WXv2W/hx7OQzDArjePrjqBQCXT+gQIHQIEDoECB0ChA4BO6vc+ebyw2F3sXdZawFmerN4/fswDIcXb18p9N3F3uLT5cPNrQrYqKfD45P/ut1HdwgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIWDnqhdwnQwPPhmd3zh9NTo//+1kk8vZOlPv3/LZL//TSq4fOzoECB0ChA4BQocAoUOA0CFA6BDgHP2dnbt3RudnXx5NPsfR92ebWs5apl7DlC+e/Do6/+bgxej8x7//GZ0//+ve6Pz40eiYGezoECB0CBA6BAgdAoQOAUKHAKFDgHP0d6auBb/17fS14mdf3594jp9WWtNFU+fkb28fjM6nruc+fvT56PyHjx+Ozqf8+dH4vnJ0Ov5/COez/nqbHR0ChA4BQocAoUOA0CFA6BAgdAhwjr5Bc8/J55r7vedTj9+fePwfX302Op96f95Ofa97/Hvv57CjQ4DQIUDoECB0CBA6BAgdAoQOAc7Rt8hV/3761PXw+9/9POv5/f755bGjQ4DQIUDoECB0CBA6BAgdAoQOAc7ReW9XfY7P+uzoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA69HZGsPE76ffOH01Oi9fT29HhwChQ4DQIUDoECB0CBA6BAgdApyjszWck6/Pjg4BQocAoUOA0CFA6BAgdAgQOgQ4R2drOCdfnx0dAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAhYDsPw/ndeLl8uFouTy1sOMNOdYRgOL964UujAdvLRHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAv4FEC5hpUGrX5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#m.pcolormesh(xi, yi, aggregate_grid);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAADrCAYAAABAZosDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADtklEQVR4nO3dMU4bURRA0XFkJUjUNDRZAmUWkILNZgNI2QRLoKFJpBRZwE9HgaLYjseese855WhAH5urZ+nZsBljTMB1+7D0AYDTEzoECB0ChA4BQocAoUPA9pCbP24+jZvp9lRnAY70e/r1c4xx9/76QaHfTLfTl83X+U4FzOr7+Pbyt+teukOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgHbpQ9wKZ5en3fe83j/cIaT8L/2eQ7/Zdfzu+v7L/n7YaJDgNAhQOgQIHQIEDoECB0ChA4B9uh7siM/3rF77FO75D35LiY6BAgdAoQOAUKHAKFDgNAhQOgQYI/Om6X33GvfY695T76LiQ4BQocAoUOA0CFA6BAgdAgQOgTYo+9pjr/rvvSe+tIdu8deeg+/JBMdAoQOAUKHAKFDgNAhQOgQIHQIsEff0zl2rGvfw5/6MTj1/y+/5j35LiY6BAgdAoQOAUKHAKFDgNAhQOgQYI9+RkvvyZfeI5c/D740Ex0ChA4BQocAoUOA0CFA6BAgdAiwR1+Ra98jX/vPt2YmOgQIHQKEDgFChwChQ4DQIUDoEGCPzmx83ny9THQIEDoECB0ChA4BQocAoUOA0CHAHp3Z2JOvl4kOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BGyXPgDr8fT6fNTXP94/zHQS5maiQ4DQIUDoECB0CBA6BAgdAoQOAUKHAG+Y4Y03vFwvEx0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoELAZY+x/82bzY5qml9MdBzjS5zHG3fuLB4UOXCYv3SFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIeAPg1BQWw7ApRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#m.pcolormesh(xi, yi, file_uhdbz);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAADrCAYAAABAZosDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADhklEQVR4nO3dMWrcUBRAUSkYx+DaTRovIWUWkCKbzQYC2USW4CaNDSmygJ/GlQnYE0ko0j2nFGP8Z+DyBh7fnscYE3Bu7/Y+ALA9oUOA0CFA6BAgdAgQOgRcXfLi6/n9uJlutzoLsNDv6dfTGOPu5fOLQr+ZbqdP8+f1TgWs6vv4+vC35766Q4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAVd7H+BMvv38sejnv3z4uNJJjum1z6/++SxhokOA0CFA6BAgdAgQOgQIHQKEDgH26M+W7sD/B2d4D2zDRIcAoUOA0CFA6BAgdAgQOgQIHQLs0Z+tcdd56/vUW993t4c/LxMdAoQOAUKHAKFDgNAhQOgQIHQIsEdf0d5/d3zp7996z2+Pvx8THQKEDgFChwChQ4DQIUDoECB0CLBHP5C99/Rb37ff+/2dmYkOAUKHAKFDgNAhQOgQIHQIEDoE2KPzZvbcx2WiQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4B7qNzGEv/f3r5Pr2JDgFChwChQ4DQIUDoECB0CBA6BNijcxrlPflrTHQIEDoECB0ChA4BQocAoUOA0CHAHp3DsCf/dyY6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAwjzHe/uJ5fpym6WG74wAL3Y8x7l4+vCh04Jh8dYcAoUOA0CFA6BAgdAgQOgQIHQKEDgFCh4A/7jM+h3GmQX8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#m.pcolormesh(xi, yi, file_tors);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one=tors_forrmse_one[(tors_forrmse_one==1)|(uhdbz_forrmse_one==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two=uhdbz_forrmse_one[(tors_forrmse_one==1)|(uhdbz_forrmse_one==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14814814814814814"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#from sklearn import metrics\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(one, two)\n",
    "#metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uhdbz_roc = uhdbz_forrmse_one[(tors_forrmse_one!=0.)|(uhdbz_forrmse_one!=0.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tors_roc = tors_forrmse_one[(tors_forrmse_one!=0.)|(uhdbz_forrmse_one!=0.)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10",
   "language": "python",
   "name": "cmip6-201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
